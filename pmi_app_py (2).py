# -*- coding: utf-8 -*-
"""pmi_app.py

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/10NNokAqvf8SiRfevbf707EO29ZrHMoBD
"""

import streamlit as st
import pandas as pd
from sklearn.cluster import KMeans
from sklearn.preprocessing import StandardScaler
import folium
from streamlit_folium import st_folium # To display folium maps in Streamlit
import io # Needed for download button formatting

# --- Streamlit Page Configuration ---
st.set_page_config(layout="wide", page_title="HCP Segmentation Tool")

st.title("Interactive HCP Segmentation Tool (POC)")
st.markdown("""
This tool helps visualize potential sales territories by clustering Healthcare Providers (HCPs).

**Instructions:**
1.  Upload a CSV file containing columns: `hcp id`, `trx count`, `lat`, `long`.
2.  Select the desired number of clusters (territories).
3.  Click 'Generate Clusters'.
4.  Review the map, summary statistics, and the full data table with assigned clusters.
5.  Download the results using the button at the bottom.
""")

# --- File Upload ---
uploaded_file = st.file_uploader("1. Upload your HCP Data (CSV)", type="csv")

if uploaded_file is not None:
    try:
        df = pd.read_csv(uploaded_file)
        st.success("File Uploaded Successfully!")

        # --- Data Validation ---
        required_columns = ['hcp id', 'trx count', 'lat', 'long']
        if not all(col in df.columns for col in required_columns):
            st.error(f"Error: CSV must contain the columns: {', '.join(required_columns)}")
            st.stop() # Stop execution if columns are missing

        st.write("### Input Data Preview (First 5 Rows)")
        st.dataframe(df.head())

        # --- Handle Missing Values (Simple Strategy: Drop Rows) ---
        initial_rows = len(df)
        # Use copy to avoid SettingWithCopyWarning when adding 'Cluster ID' later
        df_cleaned = df.dropna(subset=['trx count', 'lat', 'long']).copy()
        rows_dropped = initial_rows - len(df_cleaned)
        if rows_dropped > 0:
            st.warning(f"Warning: Dropped {rows_dropped} rows due to missing values in 'trx count', 'lat', or 'long'.")

        if len(df_cleaned) == 0:
             st.error("Error: No valid data remaining after handling missing values. Please check your input file.")
             st.stop() # Stop if no data left

        # --- User Input for Number of Clusters ---
        st.markdown("---") # Separator
        # Ensure max_value doesn't exceed the number of available data points after cleaning
        max_k = max(2, len(df_cleaned)) # At least 2 clusters, up to number of points
        k = st.number_input("2. Select the number of clusters (territories):", min_value=2, max_value=min(50, max_k), value=min(5, max_k), step=1)

        # --- Clustering Execution ---
        st.markdown("---") # Separator
        if st.button(f"3. Generate {k} Clusters", type="primary"):
            with st.spinner('Performing clustering... Please wait.'):
                # --- Feature Selection and Scaling ---
                features = ['trx count', 'lat', 'long']
                X = df_cleaned[features]

                scaler = StandardScaler()
                X_scaled = scaler.fit_transform(X)

                # --- KMeans Clustering ---
                kmeans = KMeans(n_clusters=k, init='k-means++', random_state=42, n_init=10) # Set n_init explicitly for stability
                kmeans.fit(X_scaled)
                # Assign cluster labels back to the cleaned dataframe
                df_cleaned.loc[:, 'Cluster ID'] = kmeans.labels_

                st.success(f"Clustering Complete! {k} segments generated.")
                st.markdown("---") # Separator

                # --- Display Results ---
                st.write("### 4. Segmentation Results")

                # --- Create two columns for Map and Summary ---
                col1, col2 = st.columns() # Give map more space

                with col1:
                    # 1. Map Visualization
                    st.write("#### Map Visualization")
                    st.markdown("Map showing HCP locations colored by assigned cluster.")
                    # Create a base map centered around the mean lat/lon
                    if not df_cleaned.empty:
                        map_center = [df_cleaned['lat'].mean(), df_cleaned['long'].mean()]
                    else:
                        map_center = [39.8283, -98.5795] # Default center (US approx) if empty

                    m = folium.Map(location=map_center, zoom_start=4, tiles='cartodbpositron') # Use a lighter base map

                    # Define a color scheme (using a more robust method for many clusters)
                    # Using a simple modulo approach, can be replaced with better color mapping if needed
                    colors = ['#e41a1c','#377eb8','#4daf4a','#984ea3','#ff7f00','#ffff33','#a65628','#f781bf','#999999', '#1b9e77', '#d95f02', '#7570b3', '#e7298a', '#66a61e', '#e6ab02', '#a6761d', '#666666']

                    for idx, row in df_cleaned.iterrows():
                        cluster_id = row['Cluster ID']
                        color = colors[cluster_id % len(colors)] # Cycle through colors
                        folium.CircleMarker(
                            location=[row['lat'], row['long']],
                            radius=4, # Slightly larger markers
                            popup=f"<b>HCP ID:</b> {row['hcp id']}<br>"
                                  f"<b>Trx Count:</b> {row['trx count']}<br>"
                                  f"<b>Cluster:</b> {cluster_id}",
                            tooltip=f"Cluster {cluster_id}", # Show cluster on hover
                            color=color,
                            fill=True,
                            fill_color=color,
                            fill_opacity=0.7,
                            weight=1 # Border weight
                        ).add_to(m)

                    # Display the map in Streamlit (Corrected Line)
                    st_folium(m, width=700, height=500)

                with col2:
                    # 2. Cluster Summary Statistics Table
                    st.write("#### Cluster Summary")
                    st.markdown("Key statistics for each generated cluster.")
                    cluster_summary = df_cleaned.groupby('Cluster ID').agg(
                        Number_of_HCPs=('hcp id', 'count'),
                        Average_Trx_Count=('trx count', 'mean'),
                        Total_Trx_Count=('trx count', 'sum'), # Added Total Trx
                        # Geographic_Centroid_Lat=('lat', 'mean'), # Centroid might be less intuitive than just counts/sums
                        # Geographic_Centroid_Long=('long', 'mean')
                    ).reset_index()
                    # Format for better readability
                    cluster_summary = cluster_summary.round(1)
                    # cluster_summary['Geographic_Centroid_Lat'] = cluster_summary['Geographic_Centroid_Lat'].round(4)
                    # cluster_summary['Geographic_Centroid_Long'] = cluster_summary['Geographic_Centroid_Long'].round(4)
                    st.dataframe(cluster_summary)

                st.markdown("---") # Separator

                # 3. Data Table with Cluster IDs (Full List)
                st.write("#### Full Segmented Data Table")
                st.markdown("Complete list of HCPs with their assigned Cluster ID.")
                # Display relevant columns, make dataframe interactive (sortable)
                st.dataframe(df_cleaned[['hcp id', 'trx count', 'lat', 'long', 'Cluster ID']].sort_values('Cluster ID'))

                # 4. Download Button
                st.markdown("---") # Separator
                st.write("### 5. Export Results")
                # Use BytesIO to prepare the CSV data for the download button
                output = io.BytesIO()
                # Ensure df_cleaned has the Cluster ID before saving
                df_to_save = df_cleaned[['hcp id', 'trx count', 'lat', 'long', 'Cluster ID']]
                df_to_save.to_csv(output, index=False, encoding='utf-8')
                output.seek(0) # Reset buffer position to the beginning

                st.download_button(
                    label="Download Segmented Data as CSV",
                    data=output,
                    file_name=f'hcp_segmented_data_{k}_clusters.csv',
                    mime='text/csv',
                    key='download-csv' # Add a key for stability
                )

    except pd.errors.EmptyDataError:
        st.error("Error: The uploaded CSV file is empty.")
    except Exception as e:
        st.error(f"An unexpected error occurred during processing: {e}")
        st.error("Please ensure the uploaded file is a valid CSV and has the correct format/columns.")

else:
    st.info("Awaiting CSV file upload to begin.")